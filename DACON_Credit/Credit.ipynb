{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Run_model.ipynb의 사본의 사본","private_outputs":true,"provenance":[{"file_id":"1NMOGvhMYggPaq2UxxUpjQQNuJpCW55mK","timestamp":1621413166269},{"file_id":"1L8rCEYUO8Fj9sqlVvUkpNbAKdleTKFvA","timestamp":1621410616660},{"file_id":"15AgPJsrHS4-dF3DszZDP_PPiAUjpAheF","timestamp":1621403042437},{"file_id":"16Xr5kXCHttAec78G8mVNS9HOeYij7Rlv","timestamp":1621233453124}],"collapsed_sections":["LTuBnBvGXxi2"],"authorship_tag":"ABX9TyNmSKfrHKN6vpRlTa5uWW8R"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"l3iR-seGFd9l"},"source":["!pip install scikit-learn==0.22.1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jvt77EJqFg1V"},"source":["!pip show imbalanced-learn"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"25aFYiEMFhfY"},"source":["pip install kaggler"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mKgXSPeNFicz"},"source":["import warnings\n","warnings.filterwarnings('ignore')\n","\n","import pandas as pd\n","import numpy as np\n","import random\n","import glob\n","\n","import lightgbm as lgb\n","from lightgbm import LGBMClassifier\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.metrics import log_loss\n","\n","from kaggler.model import AutoLGB\n","from kaggler.preprocessing import LabelEncoder\n","\n","from pprint import pprint\n","\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.datasets import make_classification\n","from sklearn.decomposition import PCA\n","import six\n","import sys\n","sys.modules['sklearn.externals.six'] = six\n","from sklearn.externals import six\n","from imblearn.over_sampling import SMOTE\n","from sklearn.model_selection import train_test_split\n","\n","\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3jM2YtiNFjv_"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qr9ub-z4jwlD"},"source":["def days_to_age(x) :\n","    return int(((x)/365)+1)\n","\n","def month_to_year(x) :\n","    return int(((x)/12)+1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5TwEk1l2FlZz"},"source":["PATH = './drive/MyDrive/Credit/data/'\n","train = pd.read_csv(PATH+'train.csv')\n","test = pd.read_csv(PATH+'test.csv')\n","# submit = pd.read_csv(PATH+'sample_submission.csv')\n","\n","train.drop(['index', 'FLAG_MOBIL'], inplace=True, axis=1)\n","test.drop(['index', 'FLAG_MOBIL'], inplace=True, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kp6xrfpo8wDV"},"source":["# Error Data Preprocessing\n","\n","train['family_size'][[5825, 16791, 21096, 18879, 16110]] = 3.0\n","train['family_size'][14900] = 4.0\n","train['family_size'][[10568]] = 1.0\n","train['gender'][[3603, 7078, 21930, 8576, 25641, 11828, 11121, 12984, 1393, 21770, 4443, 7942, 26008]] = 'F'\n","train['family_type'][[3064, 23249, 22262, 18305, 21027, 5825, 24754, 6683, 14287, 11308, 3890, 16110, 3138, 10279]] = 'Married'\n","train['reality'][[13036, 23381, 22828, 22133, 19893, 3138]] = 'Y'\n","train['email'][[19918, 18073, 19322]] = 1\n","train['family_type'][[26056, 10568]] = 'Widow'\n","train['edu_type'][26056] = 'Secondary / secondary special'\n","train['income_type'][[6743, 17278, 23227, 1964, 26159, 14356, 9793, 10357]] = 'Commercial associate'\n","train['income_type'][[5786, 6695]] = 'State servant'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B3-LyTSmxapl"},"source":["# iden column 추가\n","train['iden'] = train.apply(lambda x : \"\".join([str(x[i]) for i in ['DAYS_BIRTH', 'income_total', 'DAYS_EMPLOYED', 'family_type', 'gender']]), axis=1)\n","test['iden'] = test.apply(lambda x : \"\".join([str(x[i]) for i in ['DAYS_BIRTH', 'income_total', 'DAYS_EMPLOYED', 'family_type', 'gender']]), axis=1)\n","\n","# child_num이 5보다 큰 데이터는 삭제 -> 추후에 적용 예정\n","train = train[train['child_num'] <= 5]\n","# 16654, 4512\n","train.drop([1561, 20920, 8576, 9196, 13105], inplace=True)\n","train.reset_index(drop=True, inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8vRyhifaFmW8"},"source":["df = pd.concat([train.drop(['credit'], axis=1), test])\n","df.loc[df['DAYS_EMPLOYED']>0, 'DAYS_EMPLOYED'] = 0\n","df.loc[df['DAYS_EMPLOYED'] == 0, 'occyp_type'] = 'Unemployed'\n","df.fillna('Unknown', inplace=True)\n","\n","for minus in ['DAYS_BIRTH', 'DAYS_EMPLOYED', 'begin_month'] :\n","    df[minus] = -df[minus].astype(int)\n","\n","df['family_size'] = df['family_size'].astype(int)\n","df['income_total'] = df['income_total'].astype(int)\n","df['life'] = (df['income_total']/df['family_size']).astype(int)\n","\n","df['before_EMPLOYED']=df['DAYS_BIRTH']-df['DAYS_EMPLOYED']\n","df['before_EMPLOYED_month']=np.floor((df['before_EMPLOYED'])/30)-((np.floor((df['before_EMPLOYED'])/30)/12).astype(int)*12)\n","df['before_EMPLOYED_week']=np.floor((df['before_EMPLOYED'])/7)-((np.floor((df['before_EMPLOYED'])/7)/4).astype(int)*4)\n","\n","df['DAYS_BIRTH_month']=np.floor((df['DAYS_BIRTH'])/30)-((np.floor((df['DAYS_BIRTH'])/30)/12).astype(int)*12)\n","df['DAYS_BIRTH_week']=np.floor((df['DAYS_BIRTH'])/7)-((np.floor((df['DAYS_BIRTH'])/7)/4).astype(int)*4)\n","\n","df['DAYS_EMPLOYED_month']=np.floor((df['DAYS_EMPLOYED'])/30)-((np.floor((df['DAYS_EMPLOYED'])/30)/12).astype(int)*12)\n","df['DAYS_EMPLOYED_week']=np.floor((df['DAYS_EMPLOYED'])/7)-((np.floor((df['DAYS_EMPLOYED'])/7)/4).astype(int)*4)\n","\n","df['gen_fam_type'] = df.apply(lambda x : str(x['gender'])+'_'+str(x['family_type']), axis=1)\n","df['real_car'] = df.apply(lambda x : str(x['reality'])+'_'+str(x['car']), axis=1)\n","\n","df['fam_ts'] = df.apply(lambda x : str(x['family_type'])+'_'+str(x['family_size']), axis=1)\n","df['gen_income'] = df.apply(lambda x : str(x['gender'])+'_'+str(x['income_type']), axis=1)\n","df['gen_worktype'] = df.apply(lambda x : str(x['gender'])+'_'+str(x['occyp_type']), axis=1)\n","df['fc'] = df['family_size'] - df['child_num']\n","\n","df['begin_year'] = df['begin_month']//12\n","\n","df['iden_begin'] = df.apply(lambda x : str(x['iden'])+'_'+str(x['begin_year']), axis=1)\n","df['fam_house'] = df.apply(lambda x : str(x['house_type'])+'_'+str(x['family_size']), axis=1)\n","df['gen_work'] = df.apply(lambda x : str(x['gender'])+'_'+str(x['work_phone']), axis=1)\n","df['age_gen'] = df['DAYS_BIRTH'].apply(lambda x : '60' if days_to_age(x)//10*10 >= 60 else ( '10' if days_to_age(x)//10*10 < 20 else str(days_to_age(x)//10*10)))+ '_' + df['gender']\n","df['income_edu'] = df.apply(lambda x : str(x['edu_type'])+'_'+str(x['income_type']), axis=1)\n","df['age'] =  df['DAYS_BIRTH'].apply(lambda x : '60' if days_to_age(x)//10*10 >= 60 else ( '10' if days_to_age(x)//10*10 < 20 else str(days_to_age(x)//10*10)))\n","\n","df.drop(['begin_year'], axis=1, inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eBUtNL00GA_C"},"source":["edu_dict = {'Academic degree' : 4, # 학사 이상\n","            'Higher education' : 3, # 고등학교 졸업\n","            'Incomplete higher' : 2, # 고등학교 중퇴\n","           'Secondary / secondary special' : 1, # 중학교\n","            'Lower secondary' : 0} # 중학교 미만\n","\n","df['edu_type'] = df['edu_type'].apply(lambda x: edu_dict[x])\n","\n","ob_col = list(set([x for x in df.columns if df[x].dtype == 'object']))\n","\n","lbe = LabelEncoder(min_obs=10)\n","df[ob_col] = lbe.fit_transform(df[ob_col])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cD1DILFlXfeg"},"source":["y = train['credit']\n","n_trn = train.shape[0]\n","X = df.iloc[:n_trn]\n","X_tst = df.iloc[n_trn:]\n","\n","n_class = 3\n","n_fold = 5\n","\n","cv = StratifiedKFold(n_splits=n_fold, random_state=42)\n","\n","p = np.zeros((X.shape[0], n_class), dtype=float)\n","p_tst = np.zeros((X_tst.shape[0], n_class), dtype=float)\n","\n","params={'bagging_freq': 1, 'verbosity': -1, 'seed': 42, 'num_threads': -1, 'feature_pre_filter': False,\\\n","        'num_class': 3, 'objective': 'multiclass', 'metric': 'multi_logloss', 'boosting': 'gbdt',\\\n","        'bagging_fraction': 0.7000000000000001, 'feature_fraction': 0.5, 'lambda_l1': 0,\\\n","        'lambda_l2': 10, 'learning_rate': 0.04881102117105835, 'max_depth': -1,\\\n","        'min_child_samples': 10, 'num_leaves': 255}\n","features = df.columns\n","n_best = 259\n","for i_cv, (i_trn, i_val) in enumerate(cv.split(X, y)):\n","    train_data = lgb.Dataset(X[features].iloc[i_trn], label=y[i_trn])\n","    clf = lgb.train(params, train_data, n_best, verbose_eval=100)\n","    \n","    p[i_val] = clf.predict(X[features].iloc[i_val])\n","    p_tst += clf.predict(X_tst[features]) / n_fold\n","\n","from sklearn.metrics import log_loss\n","print(f'CV Log Loss: {log_loss(y, p):f}')\n","submit = pd.read_csv(PATH+'sample_submission.csv')\n","\n","submit[submit.columns[1:]] = p_tst\n","submit.to_csv('20210519_01.csv', index=False)\n","def get_ans(df) :\n","    df.drop(['index'], axis=1, inplace=True)\n","    temp = pd.Series(df.apply(lambda x : 0 if x['0'] == max(x) else ( 1 if x['1'] == max(x) else 2),  axis=1))\n","    display(temp.value_counts()/len(temp))\n","\n","get_ans(submit)\n","submit['predict'] = submit.apply(lambda x : 0 if x['0'] == max(x) else ( 1 if x['1'] == max(x) else 2),  axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2h1DLkBiofh4"},"source":["CV Log Loss: 0.699465\n","2    0.8113\n","1    0.1437\n","0    0.0450"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0q1vEsGYZEiO"},"source":["clf.feature_name(), clf.feature_importance()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LTuBnBvGXxi2"},"source":["\n","### 중복 데이터를 없애버림\n","* CV Log Loss: 0.754563  \n","2    0.9049  \n","1    0.0851  \n","0    0.0100\n","\n","* real_car\n","    * CV Log Loss: 0.731970  \n","2    0.8478  \n","1    0.1215  \n","0    0.0307\n",">실제 점수 7.06  \n","\n","-----------------\n","\n","\n","### 아무 전처리를 하지 않았을 때\n","* CV Log Loss: 0.729974  \n","2    0.9004  \n","1    0.0871  \n","0    0.0125  \n","\n","* 추가 전처리\n","    * CV Log Loss: 0.703694  \n","2    0.8199  \n","1    0.1374  \n","0    0.0427\n",">실제 점수 7.04  \n","\n","----------------\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"xtby_mDxYufq"},"source":["## 전처리 순서\n","\n","1. DAYS_EMPLOYED>0인 데이터를 0으로 만들어준다.  \n","    1-1. 그 데이터의 occyp_type에 unemploed 부여  \n","    1-2. 남은 occyp_type Null 값 fillna()  \n","<br>\n","2. child_num이 family_num보다 큰 이상 데이터 삭제  \n","    2-1. child_num이 5초과 데이터 삭제  \n","<br>  \n","\n","3. Gender와 AGE 변수를 합하여 age_gen 변수 생성  \n","    3-1. 'gender' 변수는 그대로 두는 것이 좋음  \n","    3-2. 'age' 추가는 고려, 안하는 게 나은 듯  \n","    3-3. family와 child의 차이인 fc도 고려만, 안하는게 좋은듯  \n","<br>\n","4. income_total을 family_size로 나눈 life 변수 생성  \n","    4-1. ['income_total'] normalize  \n","        * MinMax보다 Zscor가 좋음\n","        * 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'begin_month'은 나중에 고려  \n","    4-2. child 컬럼 삭제\n","\n","5. before_EMPLOYED 컬럼 추가, month, week\n","6. real_car 추가 후, reality, car 삭제\n","    * email, phone은 의미있는 변수\n","\n","\n","예외\n","중복 데이터 처리"]},{"cell_type":"code","metadata":{"id":"JgrkBGRQ25QV"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FujptUfoi1un"},"source":[],"execution_count":null,"outputs":[]}]}